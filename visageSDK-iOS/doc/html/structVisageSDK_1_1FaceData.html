<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>visageSDK: VisageSDK::FaceData Struct Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">visageSDK
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.2 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>VisageSDK</b></li><li class="navelem"><a class="el" href="structVisageSDK_1_1FaceData.html">FaceData</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="structVisageSDK_1_1FaceData-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">VisageSDK::FaceData Struct Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Face data structure, used as container for all face tracking and detection results.  
 <a href="structVisageSDK_1_1FaceData.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="FaceData_8h_source.html">FaceData.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a6aca0c311aeb0b3ee0eead93546235dd"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a6aca0c311aeb0b3ee0eead93546235dd">trackingQuality</a></td></tr>
<tr class="memdesc:a6aca0c311aeb0b3ee0eead93546235dd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tracking quality level.  <a href="#a6aca0c311aeb0b3ee0eead93546235dd"></a><br/></td></tr>
<tr class="separator:a6aca0c311aeb0b3ee0eead93546235dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7138a72d57adc5ddb75d757bf0653dc1"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a7138a72d57adc5ddb75d757bf0653dc1">frameRate</a></td></tr>
<tr class="memdesc:a7138a72d57adc5ddb75d757bf0653dc1"><td class="mdescLeft">&#160;</td><td class="mdescRight">The frame rate of the tracker, in frames per second, measured over last 10 frames.  <a href="#a7138a72d57adc5ddb75d757bf0653dc1"></a><br/></td></tr>
<tr class="separator:a7138a72d57adc5ddb75d757bf0653dc1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7afec396f9581356cc0b8fea4a10b9b"><td class="memItemLeft" align="right" valign="top">long&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#af7afec396f9581356cc0b8fea4a10b9b">timeStamp</a></td></tr>
<tr class="memdesc:af7afec396f9581356cc0b8fea4a10b9b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Timestamp of the current video frame.  <a href="#af7afec396f9581356cc0b8fea4a10b9b"></a><br/></td></tr>
<tr class="separator:af7afec396f9581356cc0b8fea4a10b9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a854b784b183fa4021e713506deff9845"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a854b784b183fa4021e713506deff9845">faceTranslation</a> [3]</td></tr>
<tr class="memdesc:a854b784b183fa4021e713506deff9845"><td class="mdescLeft">&#160;</td><td class="mdescRight">Translation of the head from the camera.  <a href="#a854b784b183fa4021e713506deff9845"></a><br/></td></tr>
<tr class="separator:a854b784b183fa4021e713506deff9845"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5fe0bbe5ca937e2f2070c9fe07f3b82"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#ab5fe0bbe5ca937e2f2070c9fe07f3b82">faceRotation</a> [3]</td></tr>
<tr class="memdesc:ab5fe0bbe5ca937e2f2070c9fe07f3b82"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rotation of the head.  <a href="#ab5fe0bbe5ca937e2f2070c9fe07f3b82"></a><br/></td></tr>
<tr class="separator:ab5fe0bbe5ca937e2f2070c9fe07f3b82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a756d9a030db04d3e8686d8edd9c385ef"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a756d9a030db04d3e8686d8edd9c385ef">gazeDirection</a> [2]</td></tr>
<tr class="memdesc:a756d9a030db04d3e8686d8edd9c385ef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gaze direction.  <a href="#a756d9a030db04d3e8686d8edd9c385ef"></a><br/></td></tr>
<tr class="separator:a756d9a030db04d3e8686d8edd9c385ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a163adbed757c776cf6ce7556ec226e58"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a163adbed757c776cf6ce7556ec226e58">gazeDirectionGlobal</a> [3]</td></tr>
<tr class="memdesc:a163adbed757c776cf6ce7556ec226e58"><td class="mdescLeft">&#160;</td><td class="mdescRight">Global gaze direction, taking into account both head pose and eye rotation.  <a href="#a163adbed757c776cf6ce7556ec226e58"></a><br/></td></tr>
<tr class="separator:a163adbed757c776cf6ce7556ec226e58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c494a1b319a79eade8191cd7e9b7b4c"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a4c494a1b319a79eade8191cd7e9b7b4c">eyeClosure</a> [2]</td></tr>
<tr class="memdesc:a4c494a1b319a79eade8191cd7e9b7b4c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Discrete eye closure value.  <a href="#a4c494a1b319a79eade8191cd7e9b7b4c"></a><br/></td></tr>
<tr class="separator:a4c494a1b319a79eade8191cd7e9b7b4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c65746338cc1236659c950014b02f9d"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a0c65746338cc1236659c950014b02f9d">shapeUnitCount</a></td></tr>
<tr class="memdesc:a0c65746338cc1236659c950014b02f9d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of facial Shape Units.  <a href="#a0c65746338cc1236659c950014b02f9d"></a><br/></td></tr>
<tr class="separator:a0c65746338cc1236659c950014b02f9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bc3d34519d420010cab7829c5d24b85"><td class="memItemLeft" align="right" valign="top">float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a7bc3d34519d420010cab7829c5d24b85">shapeUnits</a></td></tr>
<tr class="memdesc:a7bc3d34519d420010cab7829c5d24b85"><td class="mdescLeft">&#160;</td><td class="mdescRight">List of current values for facial Shape Units, one value for each shape unit.  <a href="#a7bc3d34519d420010cab7829c5d24b85"></a><br/></td></tr>
<tr class="separator:a7bc3d34519d420010cab7829c5d24b85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05248f4d533bb6e4977ecba4eeb866d0"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a05248f4d533bb6e4977ecba4eeb866d0">actionUnitCount</a></td></tr>
<tr class="memdesc:a05248f4d533bb6e4977ecba4eeb866d0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of facial Action Units.  <a href="#a05248f4d533bb6e4977ecba4eeb866d0"></a><br/></td></tr>
<tr class="separator:a05248f4d533bb6e4977ecba4eeb866d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49a558930595aea1140415bc4acf3aba"><td class="memItemLeft" align="right" valign="top">int *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a49a558930595aea1140415bc4acf3aba">actionUnitsUsed</a></td></tr>
<tr class="memdesc:a49a558930595aea1140415bc4acf3aba"><td class="mdescLeft">&#160;</td><td class="mdescRight">Used facial Action Units.  <a href="#a49a558930595aea1140415bc4acf3aba"></a><br/></td></tr>
<tr class="separator:a49a558930595aea1140415bc4acf3aba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fe570893d3cfda329549c2432450e5f"><td class="memItemLeft" align="right" valign="top">float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a7fe570893d3cfda329549c2432450e5f">actionUnits</a></td></tr>
<tr class="memdesc:a7fe570893d3cfda329549c2432450e5f"><td class="mdescLeft">&#160;</td><td class="mdescRight">List of current values for facial Action Units, one value for each action unit.  <a href="#a7fe570893d3cfda329549c2432450e5f"></a><br/></td></tr>
<tr class="separator:a7fe570893d3cfda329549c2432450e5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b816d03c066223724aac966ec535deb"><td class="memItemLeft" align="right" valign="top">const char **&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a3b816d03c066223724aac966ec535deb">actionUnitsNames</a></td></tr>
<tr class="memdesc:a3b816d03c066223724aac966ec535deb"><td class="mdescLeft">&#160;</td><td class="mdescRight">List of facial Action Units names.  <a href="#a3b816d03c066223724aac966ec535deb"></a><br/></td></tr>
<tr class="separator:a3b816d03c066223724aac966ec535deb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af15daaee4a0e1f4f60087ec2c3839588"><td class="memItemLeft" align="right" valign="top">FBAPs *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#af15daaee4a0e1f4f60087ec2c3839588">faceAnimationParameters</a></td></tr>
<tr class="memdesc:af15daaee4a0e1f4f60087ec2c3839588"><td class="mdescLeft">&#160;</td><td class="mdescRight">MPEG-4 facial animation parameters.  <a href="#af15daaee4a0e1f4f60087ec2c3839588"></a><br/></td></tr>
<tr class="separator:af15daaee4a0e1f4f60087ec2c3839588"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fd85018c51af5c63ac2d60eb6c9d91a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classVisageSDK_1_1FDP.html">FDP</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a1fd85018c51af5c63ac2d60eb6c9d91a">featurePoints3D</a></td></tr>
<tr class="memdesc:a1fd85018c51af5c63ac2d60eb6c9d91a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Facial feature points (global 3D coordinates).  <a href="#a1fd85018c51af5c63ac2d60eb6c9d91a"></a><br/></td></tr>
<tr class="separator:a1fd85018c51af5c63ac2d60eb6c9d91a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad64b091d44f2358f2cd0e86d7b627a99"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classVisageSDK_1_1FDP.html">FDP</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#ad64b091d44f2358f2cd0e86d7b627a99">featurePoints3DRelative</a></td></tr>
<tr class="memdesc:ad64b091d44f2358f2cd0e86d7b627a99"><td class="mdescLeft">&#160;</td><td class="mdescRight">Facial feature points (3D coordinates relative to the face origin, placed at the center between eyes).  <a href="#ad64b091d44f2358f2cd0e86d7b627a99"></a><br/></td></tr>
<tr class="separator:ad64b091d44f2358f2cd0e86d7b627a99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98c7a959cbde274d14a92ef191e7758c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classVisageSDK_1_1FDP.html">FDP</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a98c7a959cbde274d14a92ef191e7758c">featurePoints2D</a></td></tr>
<tr class="memdesc:a98c7a959cbde274d14a92ef191e7758c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Facial feature points (2D coordinates).  <a href="#a98c7a959cbde274d14a92ef191e7758c"></a><br/></td></tr>
<tr class="separator:a98c7a959cbde274d14a92ef191e7758c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc8b508113ddfce9ddc012420920ce40"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#abc8b508113ddfce9ddc012420920ce40">faceModelVertexCount</a></td></tr>
<tr class="memdesc:abc8b508113ddfce9ddc012420920ce40"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of vertices in the 3D face model.  <a href="#abc8b508113ddfce9ddc012420920ce40"></a><br/></td></tr>
<tr class="separator:abc8b508113ddfce9ddc012420920ce40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e23ed5a39d923bd503e7e2fc59b10f0"><td class="memItemLeft" align="right" valign="top">float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a4e23ed5a39d923bd503e7e2fc59b10f0">faceModelVertices</a></td></tr>
<tr class="memdesc:a4e23ed5a39d923bd503e7e2fc59b10f0"><td class="mdescLeft">&#160;</td><td class="mdescRight">List of vertex coordinates of the 3D face model.  <a href="#a4e23ed5a39d923bd503e7e2fc59b10f0"></a><br/></td></tr>
<tr class="separator:a4e23ed5a39d923bd503e7e2fc59b10f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e799cc446b4bc942fdbbdf12bfab7a6"><td class="memItemLeft" align="right" valign="top">float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a9e799cc446b4bc942fdbbdf12bfab7a6">faceModelVerticesProjected</a></td></tr>
<tr class="memdesc:a9e799cc446b4bc942fdbbdf12bfab7a6"><td class="mdescLeft">&#160;</td><td class="mdescRight">List of projected (image space) vertex coordinates of the 3D face model.  <a href="#a9e799cc446b4bc942fdbbdf12bfab7a6"></a><br/></td></tr>
<tr class="separator:a9e799cc446b4bc942fdbbdf12bfab7a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a710b1440e4969cb5ad3be4cacb3c1f0e"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a710b1440e4969cb5ad3be4cacb3c1f0e">faceModelTriangleCount</a></td></tr>
<tr class="memdesc:a710b1440e4969cb5ad3be4cacb3c1f0e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of triangles in the 3D face model.  <a href="#a710b1440e4969cb5ad3be4cacb3c1f0e"></a><br/></td></tr>
<tr class="separator:a710b1440e4969cb5ad3be4cacb3c1f0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ee50ac55f282af229942fe4077b6434"><td class="memItemLeft" align="right" valign="top">int *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a8ee50ac55f282af229942fe4077b6434">faceModelTriangles</a></td></tr>
<tr class="memdesc:a8ee50ac55f282af229942fe4077b6434"><td class="mdescLeft">&#160;</td><td class="mdescRight">Triangles list for the 3D face model.  <a href="#a8ee50ac55f282af229942fe4077b6434"></a><br/></td></tr>
<tr class="separator:a8ee50ac55f282af229942fe4077b6434"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad53581671d541e68e7bf9e4619d3274"><td class="memItemLeft" align="right" valign="top">float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#aad53581671d541e68e7bf9e4619d3274">faceModelTextureCoords</a></td></tr>
<tr class="memdesc:aad53581671d541e68e7bf9e4619d3274"><td class="mdescLeft">&#160;</td><td class="mdescRight">Texture coordinates for the 3D face model.  <a href="#aad53581671d541e68e7bf9e4619d3274"></a><br/></td></tr>
<tr class="separator:aad53581671d541e68e7bf9e4619d3274"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a306fc247ad6223a52c1a840531680c1a"><td class="memItemLeft" align="right" valign="top">IplImage *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a306fc247ad6223a52c1a840531680c1a">frame</a></td></tr>
<tr class="memdesc:a306fc247ad6223a52c1a840531680c1a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pointer to the video frame associated with the current data, or NULL if tracker is not active.  <a href="#a306fc247ad6223a52c1a840531680c1a"></a><br/></td></tr>
<tr class="separator:a306fc247ad6223a52c1a840531680c1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49182e24cf549a1d6c7506b5316e60d5"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#a49182e24cf549a1d6c7506b5316e60d5">faceScale</a></td></tr>
<tr class="memdesc:a49182e24cf549a1d6c7506b5316e60d5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Scale of facial bounding box.  <a href="#a49182e24cf549a1d6c7506b5316e60d5"></a><br/></td></tr>
<tr class="separator:a49182e24cf549a1d6c7506b5316e60d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3c8554e62965d5bac968c3e4aa5ec82"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#af3c8554e62965d5bac968c3e4aa5ec82">cameraFocus</a></td></tr>
<tr class="memdesc:af3c8554e62965d5bac968c3e4aa5ec82"><td class="mdescLeft">&#160;</td><td class="mdescRight">Focal distance of the camera, as configured in the <a href="../VisageTracker Configuration Manual.pdf">tracker/detector configuration</a> file.  <a href="#af3c8554e62965d5bac968c3e4aa5ec82"></a><br/></td></tr>
<tr class="separator:af3c8554e62965d5bac968c3e4aa5ec82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa666a789971fb67bd4e485c505ba61b"><td class="memItemLeft" align="right" valign="top">ScreenSpaceGazeData&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structVisageSDK_1_1FaceData.html#afa666a789971fb67bd4e485c505ba61b">gazeData</a></td></tr>
<tr class="memdesc:afa666a789971fb67bd4e485c505ba61b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Structure holding screen space gaze position and quality for current frame.  <a href="#afa666a789971fb67bd4e485c505ba61b"></a><br/></td></tr>
<tr class="separator:afa666a789971fb67bd4e485c505ba61b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Face data structure, used as container for all face tracking and detection results. </p>
<p>This structure is passed as parameter to the <a class="el" href="classVisageSDK_1_1VisageTracker2.html#a888cf5073a33bc7658e193c0a39fedce" title="Get face data and status.">VisageTracker2::getTrackingData()</a>, <a class="el" href="classVisageSDK_1_1VisageTracker2.html#a3534b35c06db96b83d627d94b6bb0527" title="Performs face tracking in the given image and returns tracking results and status.">VisageTracker2::track()</a> or <a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#a6dddc25bbc05aa8f500cbdc0d97834fc" title="Performs faces and facial features detection in a still image.">VisageFeaturesDetector::detectFacialFeatures()</a> method. Any of these methods copies latest tracking or detection results into it.</p>
<p>When filling the structure with data some members are filled while some are left undefined depending on tracking/detection status.</p>
<h2>Obtaining tracking data</h2>
<p>The tracker returns these main classes of data:</p>
<ul>
<li>3D head pose</li>
<li>facial expression</li>
<li>gaze direction</li>
<li>eye closure</li>
<li>facial feature points</li>
<li>full 3D face model, textured</li>
<li>screen space gaze position (if calibrated)</li>
<li>detected credit card stripe for size adjustment.</li>
</ul>
<p>The tracker status is the return value of the <a class="el" href="classVisageSDK_1_1VisageTracker2.html#a888cf5073a33bc7658e193c0a39fedce" title="Get face data and status.">VisageTracker2::getTrackingData()</a> or <a class="el" href="classVisageSDK_1_1VisageTracker2.html#a3534b35c06db96b83d627d94b6bb0527" title="Performs face tracking in the given image and returns tracking results and status.">VisageTracker2::track()</a> functions. The following table describes the possible states of the tracker, and lists active member variables (those that are filled with data) for each status. </p>
<table class="doxtable">
<tr>
<td width="100"><b>TRACKER STATUS</b></td><td><b>DESCRIPTION</b></td><td><b>ACTIVE VARIABLES</b> </td></tr>
<tr>
<td>TRACK_STAT_OFF</td><td>Tracker is not active, i.e. it has not yet been started, or it has been stopped. </td><td>N/A </td></tr>
<tr>
<td>TRACK_STAT_OK</td><td>Tracker is tracking normally. </td><td>trackingQuality, frameRate, frame, cameraFocus, faceScale, faceTranslation, faceRotation, faceAnimationParameters, actionUnitCount, actionUnitsUsed, actionUnits, actionUnitsNames, featurePoints3D, featurePoints3DRelative, featurePoints2D, faceModelVertexCount, faceModelVertices, faceModelVerticesProjected, faceModelTriangleCount, faceModelTriangles, faceModelTextureCoords  </td></tr>
<tr>
<td>TRACK_STAT_RECOVERING</td><td>Tracker has lost the face and is attempting to recover and continue tracking. If it can not recover within the time defined by the parameter recovery_timeout in the <a href="../VisageTracker Configuration Manual.pdf">tracker configuration file</a>, the tracker will fully re-initialize (i.e. it will assume that a new user may be present). </td><td>frameRate, frame, cameraFocus </td></tr>
<tr>
<td>TRACK_STAT_INIT</td><td>Tracker is initializing. The tracker enters this state immediately when it is started, or when it has lost the face and failed to recover (see TRACK_STAT_RECOVERING above). The initialization process is configurable through a number of parameters in the <a href="../VisageTracker Configuration Manual.pdf">tracker configuration file.</a> </td><td>frameRate, frame, cameraFocus  </td></tr>
</table>
<h3>Smoothing</h3>
<p>Most of the tracking data can be smoothed to reduce the tracking noise. The tracker applies smoothing separately on different groups of tracking results such as head translation, rotation, gaze, etc. The smoothing factor is set separately for each group. Smoothing is adaptive, i.e. it is automatically reduced when fast motion is detected, resulting in steady values when motion is slow or static, while avoiding delay for fast motion. For more details, see the smoothing_factors parameter array in the <a href="../VisageTracker Configuration Manual.pdf">VisageTracker Configuration Manual</a>.</p>
<h2>Obtaining detection data</h2>
<p>The detector returns these main classes of data:</p>
<ul>
<li>3D head pose</li>
<li>gaze direction</li>
<li>eye closure</li>
<li>facial feature points</li>
<li>full 3D face model, textured.</li>
</ul>
<p>Detection result is returned from <a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#a6dddc25bbc05aa8f500cbdc0d97834fc" title="Performs faces and facial features detection in a still image.">VisageFeaturesDetector::detectFacialFeatures()</a> function. The following table describes possible output from the detector and the list of active variables (those that are filled with data). All other variables are left undefined. </p>
<table class="doxtable">
<tr>
<td width="100"><b>DETECTION RESULT</b></td><td><b>DESCRIPTION</b></td><td><b>ACTIVE VARIABLES</b> </td></tr>
<tr>
<td>0 </td><td>Detector did not find any faces in the image </td><td>N/A </td></tr>
<tr>
<td>N &gt; 0 </td><td>Detector detected N faces in the image. </td><td><b>For first N <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a> objects in the array:</b> cameraFocus, faceTranslation, faceRotation, featurePoints3D, featurePoints3DRelative, featurePoints2D, faceModelVertexCount, faceModelVertices, faceModelVerticesProjected, faceModelTriangleCount, faceModelTriangles, faceModelTextureCoords <br/>
 <b>For other <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a> objects in the array:</b> N/A  </td></tr>
</table>
<h2>Returned data</h2>
<p>The following sections give an overview of main classes of data that may be returned in <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a>, and pointers to specific data members.</p>
<h3>3D head pose</h3>
<p>The 3D head pose consists of head translation and rotation. It is available as absolute pose of the head with respect to the camera.</p>
<p>The following member variables return the head pose:</p>
<ul>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a854b784b183fa4021e713506deff9845" title="Translation of the head from the camera.">faceTranslation</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#ab5fe0bbe5ca937e2f2070c9fe07f3b82" title="Rotation of the head.">faceRotation</a></li>
</ul>
<p>Both face tracker and face detector return the 3D head pose.</p>
<h3>Facial expression</h3>
<p>Facial expression is available in two forms: MPEG-4 FAPs and Action Units.</p>
<p>MPEG-4 facial animation parameters (FAPs) are returned in <a class="el" href="structVisageSDK_1_1FaceData.html#af15daaee4a0e1f4f60087ec2c3839588" title="MPEG-4 facial animation parameters.">faceAnimationParameters</a>; more information about MPEG-4 FAPs is available in <a href="../MPEG-4 FBA Overview.pdf">MPEG-4 FAPs overview</a>.</p>
<p>Action Units (AUs) are the internal representation of facial motion used by the tracker, while MPEG-4 FAPs are derived. It is therefore more accurate to use the AUs directly. It should be noted that AUs are <a href="../VisageTracker Configuration Manual.pdf">fully configurable</a> in the tracker configuration files (specifically, in the 3D model file, .wfm). Please note that the AUs are similar, but not identical to the FACS Action Units.</p>
<p>The following member variables return Action Units data:</p>
<ul>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a05248f4d533bb6e4977ecba4eeb866d0" title="Number of facial Action Units.">actionUnitCount</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a49a558930595aea1140415bc4acf3aba" title="Used facial Action Units.">actionUnitsUsed</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a7fe570893d3cfda329549c2432450e5f" title="List of current values for facial Action Units, one value for each action unit.">actionUnits</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a3b816d03c066223724aac966ec535deb" title="List of facial Action Units names.">actionUnitsNames</a></li>
</ul>
<p>Only face tracker returns the facial expression; face detector leaves these variables undefined.</p>
<h3>Gaze direction and eye closure</h3>
<p>Gaze direction is available in local coordinate system of the person's face or global coordinate system of the camera. Eye closure is available as binary information (OPEN/CLOSED).</p>
<p>The following member variables return gaze direction and eye closure:</p>
<ul>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a756d9a030db04d3e8686d8edd9c385ef" title="Gaze direction.">gazeDirection</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a163adbed757c776cf6ce7556ec226e58" title="Global gaze direction, taking into account both head pose and eye rotation.">gazeDirectionGlobal</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a4c494a1b319a79eade8191cd7e9b7b4c" title="Discrete eye closure value.">eyeClosure</a></li>
</ul>
<p>Both face tracker and face detector return gaze direction and eye closure.</p>
<h3>Facial feature points</h3>
<p>2D or 3D coordinates of facial feature points, including the ones defined by the <a href="../MPEG-4 FBA Overview.pdf">MPEG-4 FBA standard</a> and some additional points are available.</p>
<p>3D coordinates are available in global coordinate system or relative to the origin of the face (i.e. the point in the center between the eyes in the input image).</p>
<p>Facial features are available through the following member variables:</p>
<ul>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a1fd85018c51af5c63ac2d60eb6c9d91a" title="Facial feature points (global 3D coordinates).">featurePoints3D</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#ad64b091d44f2358f2cd0e86d7b627a99" title="Facial feature points (3D coordinates relative to the face origin, placed at the center between eyes)...">featurePoints3DRelative</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a98c7a959cbde274d14a92ef191e7758c" title="Facial feature points (2D coordinates).">featurePoints2D</a></li>
</ul>
<p>Both face tracker and face detector return facial feature points.</p>
<h3>3D face model</h3>
<p>This is the face model used internally by the tracker or detector. The model is fitted in 3D to the face in the current image/video frame. The model is a single textured 3D triangle mesh. The mesh is fairly coarse, with approximately 200 triangles. The texture of the model is the current image/video frame. This means that, when the model is drawn using the correct perspective it exactly recreates the facial part of the image. The correct perspective is defined by camera focal length (<a class="el" href="structVisageSDK_1_1FaceData.html#af3c8554e62965d5bac968c3e4aa5ec82" title="Focal distance of the camera, as configured in the tracker/detector configuration file...">cameraFocus</a>), width and height of the input image or the video frame (<a class="el" href="structVisageSDK_1_1FaceData.html#a306fc247ad6223a52c1a840531680c1a" title="Pointer to the video frame associated with the current data, or NULL if tracker is not active...">frame</a>), model rotation (<a class="el" href="structVisageSDK_1_1FaceData.html#ab5fe0bbe5ca937e2f2070c9fe07f3b82" title="Rotation of the head.">faceRotation</a>) and translation (<a class="el" href="structVisageSDK_1_1FaceData.html#a854b784b183fa4021e713506deff9845" title="Translation of the head from the camera.">faceTranslation</a>) - this <a href="../ar-notes.cpp">example code</a> shows how to do this using OpenGL.</p>
<p>There are multiple potential uses for the face model. Some ideas include, but are not limited to:</p>
<ul>
<li>Draw the 3D face model into the Z buffer to achieve correct occlusion of virtual objects by the head in AR applications.</li>
<li>Use texture coordinates to cut out the face from the image. (NOTE: if this is the desired effect, the model with closed mouth should be used otherwise when the mouth opens a hole appears. The model candide3-ClosedMouth.wfm is provided for this purpose and should simply be specified instead of the default Candide3.wfm in the model_filename statement in the <a href="../VisageTracker Configuration Manual.pdf">tracker/detector configuration file</a>).</li>
<li>Draw the 3D face model from a different perspective than the one in the actual video.</li>
<li><p class="startli">Insert the 3D face model into another video or 3D scene.</p>
<p class="startli">The sample projects <a href="../tracker.html">VisageTrackerDemo</a> and <a href="../unity_ar.html">VisageTrackerUnityDemo</a> both demonstrate how to access the 3D model information and display the model correctly aligned with the face image.</p>
</li>
</ul>
<p>Note that the vertices of the face model do not always exactly correspond to the facial feature points obtained from tracking/detection (featurePoints3D). For applications where the precise positioning of the facial feature points is important (e.g. virtual make-up), it is important to use the featurePoints3D and not the face model.</p>
<p>The 3D face model is contained in the following members:</p>
<ul>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#abc8b508113ddfce9ddc012420920ce40" title="Number of vertices in the 3D face model.">faceModelVertexCount</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a4e23ed5a39d923bd503e7e2fc59b10f0" title="List of vertex coordinates of the 3D face model.">faceModelVertices</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a710b1440e4969cb5ad3be4cacb3c1f0e" title="Number of triangles in the 3D face model.">faceModelTriangleCount</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#a8ee50ac55f282af229942fe4077b6434" title="Triangles list for the 3D face model.">faceModelTriangles</a></li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html#aad53581671d541e68e7bf9e4619d3274" title="Texture coordinates for the 3D face model.">faceModelTextureCoords</a></li>
</ul>
<p>Both face tracker and face detector return the 3D face model.</p>
<h3>Screen space gaze position</h3>
<p>Screen space gaze position is available if the tracker was provided with calibration repository and screen space gaze estimator is working in real time mode. Otherwise tracker returns default screen space gaze data. Default gaze position is center of screen. Default estimator state is off (ScreenSpaceGazeData::inState == 0). Please refer to <a class="el" href="classVisageSDK_1_1VisageGazeTracker.html" title="VisageGazeTracker extends VisageTracker2 functionality, adding screen space gaze tracking on top of f...">VisageGazeTracker</a> documentation for instructions on usage of screen space gaze estimator.</p>
<p>Screen space gaze position is contained in member <a class="el" href="structVisageSDK_1_1FaceData.html#afa666a789971fb67bd4e485c505ba61b" title="Structure holding screen space gaze position and quality for current frame.">gazeData</a>.</p>
<p>Only face tracker returns screen space gaze position.</p>
<h3>Credit card strip data</h3>
<p>Detection of a standard-size credit card stripe is used for size adjustment. The search can be performed only while the tracker is tracking a face. Credit card strip data can be obtained using <a class="el" href="classVisageSDK_1_1VisageTracker2.html#a1767523ef2565e4bb8c345e81a5edffb" title="Detects a credit card magnetic stripe in the current frame.">VisageTracker2::DetectStrip()</a> method. If magnetic card stripe is visible in the image, method will return its size and it can be used as reference for the size of other objects in the image.</p>
<p>Only face tracker returns credit card strip data. </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00253">253</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>
</div><h2 class="groupheader">Member Data Documentation</h2>
<a class="anchor" id="a05248f4d533bb6e4977ecba4eeb866d0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageSDK::FaceData::actionUnitCount</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of facial Action Units. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK). Face detector leaves this variable undefined.</em></p>
<p>Number of action units that are defined for current face model.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a7fe570893d3cfda329549c2432450e5f" title="List of current values for facial Action Units, one value for each action unit.">actionUnits</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a49a558930595aea1140415bc4acf3aba" title="Used facial Action Units.">actionUnitsUsed</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a3b816d03c066223724aac966ec535deb" title="List of facial Action Units names.">actionUnitsNames</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00453">453</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a7fe570893d3cfda329549c2432450e5f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float* VisageSDK::FaceData::actionUnits</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>List of current values for facial Action Units, one value for each action unit. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK). Face detector leaves this variable undefined.</em></p>
<p>The action units used by the tracker are defined in the 3D face model file (currently, Candide3.wfm is used; tracker can be configured to use another file; see the <a href="../VisageTracker Configuration Manual.pdf">VisageTracker Configuration Manual</a> for details). Furthermore, the tracker configuration file defines the names of action units and these names can be accessed through actionUnitsNames. Please refer to section or <a href="../VisageTracker Configuration Manual.pdf">VisageTracker Configuration Manual</a> for full list of action units for each tracker configuration.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a49a558930595aea1140415bc4acf3aba" title="Used facial Action Units.">actionUnitsUsed</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a05248f4d533bb6e4977ecba4eeb866d0" title="Number of facial Action Units.">actionUnitCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a3b816d03c066223724aac966ec535deb" title="List of facial Action Units names.">actionUnitsNames</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00479">479</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a3b816d03c066223724aac966ec535deb"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const char** VisageSDK::FaceData::actionUnitsNames</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>List of facial Action Units names. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK). Face detector leaves this variable undefined.</em></p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a49a558930595aea1140415bc4acf3aba" title="Used facial Action Units.">actionUnitsUsed</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a05248f4d533bb6e4977ecba4eeb866d0" title="Number of facial Action Units.">actionUnitCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a7fe570893d3cfda329549c2432450e5f" title="List of current values for facial Action Units, one value for each action unit.">actionUnits</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00490">490</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a49a558930595aea1140415bc4acf3aba"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int* VisageSDK::FaceData::actionUnitsUsed</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Used facial Action Units. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK). Face detector leaves this variable undefined.</em></p>
<p>List of values, one for each action unit, to determine if specific action unit is actually used in the current tracker configuration. Values are as follows: 1 if action unit is used, 0 if action unit is not used.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a7fe570893d3cfda329549c2432450e5f" title="List of current values for facial Action Units, one value for each action unit.">actionUnits</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a05248f4d533bb6e4977ecba4eeb866d0" title="Number of facial Action Units.">actionUnitCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a3b816d03c066223724aac966ec535deb" title="List of facial Action Units names.">actionUnitsNames</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00464">464</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="af3c8554e62965d5bac968c3e4aa5ec82"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float VisageSDK::FaceData::cameraFocus</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Focal distance of the camera, as configured in the <a href="../VisageTracker Configuration Manual.pdf">tracker/detector configuration</a> file. </p>
<p><em>This variable is set while tracker is running (any status other than TRACK_STAT_OFF), or if the detector has detected a face.</em></p>
<p>Focal length of a pinhole camera model used as approximation for the camera used to capture the video in which tracking is performed. The value is defined as distance from the camera (pinhole) to an imaginary projection plane where the smaller dimension of the projection plane is defined as 2, and the other dimension is defined by the input image aspect ratio. Thus, for example, for a landscape input image with aspect ratio of 1.33 the imaginary projection plane has height 2 and width 2.66.</p>
<p>This value is used for 3D scene set-up and accurate interpretation of tracking data.</p>
<p>Corresponding FoV (field of view) can be calculated as follows:</p>
<p>fov = 2 * atan( size / (2*cameraFocus) ), where size is 2 if width is larger than height and 2*height/width otherwise.</p>
<p>This member corresponds to the camera_focus parameter in the <a href="../VisageTracker Configuration Manual.pdf">tracker/detector configuration</a> file. </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00711">711</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l00563">VisageSDK::VisageRendering::DisplayFeaturePoints()</a>, <a class="el" href="VisageRendering_8cpp_source.html#l00890">VisageSDK::VisageRendering::DisplayGaze()</a>, <a class="el" href="VisageRendering_8cpp_source.html#l00976">VisageSDK::VisageRendering::DisplayModelAxes()</a>, and <a class="el" href="VisageRendering_8cpp_source.html#l01045">VisageSDK::VisageRendering::DisplayWireFrame()</a>.</p>

</div>
</div>
<a class="anchor" id="a4c494a1b319a79eade8191cd7e9b7b4c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float VisageSDK::FaceData::eyeClosure[2]</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Discrete eye closure value. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>Index 0 represents closure of left eye. Index 1 represents closure of right eye. Value of 1 represents open eye. Value of 0 represents closed eye. </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00417">417</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l00563">VisageSDK::VisageRendering::DisplayFeaturePoints()</a>, and <a class="el" href="VisageRendering_8cpp_source.html#l00890">VisageSDK::VisageRendering::DisplayGaze()</a>.</p>

</div>
</div>
<a class="anchor" id="af15daaee4a0e1f4f60087ec2c3839588"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FBAPs* VisageSDK::FaceData::faceAnimationParameters</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>MPEG-4 facial animation parameters. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK). Face detector leaves this variable undefined.</em></p>
<p>The face animation parameters are returned as FBAPs class that contains the Face Animation Parameters (FAPs) currently estimated by the tracker. The global translation of the face is stored in the global translation Body Animation Parameters (BAPs). The specification of the FAP and BAP parameters is contained in the the <a href="../MPEG-4 FBA Overview.pdf">MPEG-4 Face and Body Animation Introduction</a>.</p>
<p>Certain parameters, like the ones on the tongue, teeth, nose and ears, can currently not be reliably estimated so they are not returned and their values are always set to zero. These parameters are:</p>
<ul>
<li>FAPs 14 - 18 (jaw thrust and shift, lips forward push)</li>
<li>FAPs 27 - 30 (eyeball thrust and pupil dilation)</li>
<li>FAPs 39 - 40 (puff cheeks)</li>
<li>FAPs 43 - 47 (tongue motion)</li>
<li>FAPs 61 - 68 (nose and ear motion)</li>
</ul>
<p>Furthermore, the parameters of the outer lip contour (51 - 60) and the corresponding parameters of the inner lip contour (4 -13) are both set to the mean value of the outer and inner lip displacement. For example, parameters 4 (vertical displacement of top inner lip) and 51 (vertical displacement of top outer lip) are both set to the same value, and this value is the mean displacement of the upper lip midpoint. </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00515">515</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="aad53581671d541e68e7bf9e4619d3274"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float* VisageSDK::FaceData::faceModelTextureCoords</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Texture coordinates for the 3D face model. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>A pair of u, v coordinates for each vertex. When <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a> is obtained from the tracker, the texture image is the current video frame, accessible through <a class="el" href="structVisageSDK_1_1FaceData.html#a306fc247ad6223a52c1a840531680c1a" title="Pointer to the video frame associated with the current data, or NULL if tracker is not active...">frame</a>. When <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a> is obtained from detector, the texture image is the input image of the detector.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#abc8b508113ddfce9ddc012420920ce40" title="Number of vertices in the 3D face model.">faceModelVertexCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a4e23ed5a39d923bd503e7e2fc59b10f0" title="List of vertex coordinates of the 3D face model.">faceModelVertices</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a9e799cc446b4bc942fdbbdf12bfab7a6" title="List of projected (image space) vertex coordinates of the 3D face model.">faceModelVerticesProjected</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a710b1440e4969cb5ad3be4cacb3c1f0e" title="Number of triangles in the 3D face model.">faceModelTriangleCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a8ee50ac55f282af229942fe4077b6434" title="Triangles list for the 3D face model.">faceModelTriangles</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00679">679</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a710b1440e4969cb5ad3be4cacb3c1f0e"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageSDK::FaceData::faceModelTriangleCount</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of triangles in the 3D face model. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#abc8b508113ddfce9ddc012420920ce40" title="Number of vertices in the 3D face model.">faceModelVertexCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a4e23ed5a39d923bd503e7e2fc59b10f0" title="List of vertex coordinates of the 3D face model.">faceModelVertices</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a9e799cc446b4bc942fdbbdf12bfab7a6" title="List of projected (image space) vertex coordinates of the 3D face model.">faceModelVerticesProjected</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a8ee50ac55f282af229942fe4077b6434" title="Triangles list for the 3D face model.">faceModelTriangles</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#aad53581671d541e68e7bf9e4619d3274" title="Texture coordinates for the 3D face model.">faceModelTextureCoords</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00659">659</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l01045">VisageSDK::VisageRendering::DisplayWireFrame()</a>.</p>

</div>
</div>
<a class="anchor" id="a8ee50ac55f282af229942fe4077b6434"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int* VisageSDK::FaceData::faceModelTriangles</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Triangles list for the 3D face model. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK), or if the detector has detected a face.</em></p>
<p>Each triangle is described by three indices into the list of vertices <a class="el" href="structVisageSDK_1_1FaceData.html#a4e23ed5a39d923bd503e7e2fc59b10f0">faceModelVertices</a> (counter-clockwise convention is used for normals direction). An illustration showing the candide face model triangle and vertex numbers is available <a href="../images/Candide3VerticesAndTriangles.png">HERE</a>.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#abc8b508113ddfce9ddc012420920ce40" title="Number of vertices in the 3D face model.">faceModelVertexCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a4e23ed5a39d923bd503e7e2fc59b10f0" title="List of vertex coordinates of the 3D face model.">faceModelVertices</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a9e799cc446b4bc942fdbbdf12bfab7a6" title="List of projected (image space) vertex coordinates of the 3D face model.">faceModelVerticesProjected</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a710b1440e4969cb5ad3be4cacb3c1f0e" title="Number of triangles in the 3D face model.">faceModelTriangleCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#aad53581671d541e68e7bf9e4619d3274" title="Texture coordinates for the 3D face model.">faceModelTextureCoords</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00669">669</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l01045">VisageSDK::VisageRendering::DisplayWireFrame()</a>.</p>

</div>
</div>
<a class="anchor" id="abc8b508113ddfce9ddc012420920ce40"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageSDK::FaceData::faceModelVertexCount</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of vertices in the 3D face model. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a4e23ed5a39d923bd503e7e2fc59b10f0" title="List of vertex coordinates of the 3D face model.">faceModelVertices</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a9e799cc446b4bc942fdbbdf12bfab7a6" title="List of projected (image space) vertex coordinates of the 3D face model.">faceModelVerticesProjected</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a710b1440e4969cb5ad3be4cacb3c1f0e" title="Number of triangles in the 3D face model.">faceModelTriangleCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a8ee50ac55f282af229942fe4077b6434" title="Triangles list for the 3D face model.">faceModelTriangles</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#aad53581671d541e68e7bf9e4619d3274" title="Texture coordinates for the 3D face model.">faceModelTextureCoords</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00618">618</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a4e23ed5a39d923bd503e7e2fc59b10f0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float* VisageSDK::FaceData::faceModelVertices</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>List of vertex coordinates of the 3D face model. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>The format of the list is x, y, z coordinate for each vertex.</p>
<p>The coordinates are in the local coordinate system of the face, with the origin (0,0,0) placed at the center between the eyes. The x-axis points laterally towards the side of the face, y-axis points up and z-axis points into the face - see illustration below.</p>
<div class="image">
<img src="../images/coord.png" alt="coord.png"/>
</div>
 <p>To transform the coordinates into the coordinate system of the camera, use faceTranslation and faceRotation.</p>
<p>If the value set for the camera focal length in the <a href="../VisageTracker Configuration Manual.pdf">tracker/detector configuration</a> file corresponds to the real camera used, the scale of the coordinates shall be in meters; otherwise the scale is not known.</p>
<p>An illustration showing the candide face model triangle and vertex numbers is available <a href="../images/Candide3VerticesAndTriangles.png">HERE</a>.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#abc8b508113ddfce9ddc012420920ce40" title="Number of vertices in the 3D face model.">faceModelVertexCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a9e799cc446b4bc942fdbbdf12bfab7a6" title="List of projected (image space) vertex coordinates of the 3D face model.">faceModelVerticesProjected</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a710b1440e4969cb5ad3be4cacb3c1f0e" title="Number of triangles in the 3D face model.">faceModelTriangleCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a8ee50ac55f282af229942fe4077b6434" title="Triangles list for the 3D face model.">faceModelTriangles</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#aad53581671d541e68e7bf9e4619d3274" title="Texture coordinates for the 3D face model.">faceModelTextureCoords</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00640">640</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l01045">VisageSDK::VisageRendering::DisplayWireFrame()</a>.</p>

</div>
</div>
<a class="anchor" id="a9e799cc446b4bc942fdbbdf12bfab7a6"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float* VisageSDK::FaceData::faceModelVerticesProjected</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>List of projected (image space) vertex coordinates of the 3D face model. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>The format of the list is x, y coordinate for each vertex. The 2D coordinates are normalised to image size so that the lower left corner of the image has coordinates 0,0 and upper right corner 1,1.</p>
<p>An illustration showing the candide face model triangle and vertex numbers is available <a href="../images/Candide3VerticesAndTriangles.png">HERE</a>.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#abc8b508113ddfce9ddc012420920ce40" title="Number of vertices in the 3D face model.">faceModelVertexCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a4e23ed5a39d923bd503e7e2fc59b10f0" title="List of vertex coordinates of the 3D face model.">faceModelVertices</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a710b1440e4969cb5ad3be4cacb3c1f0e" title="Number of triangles in the 3D face model.">faceModelTriangleCount</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a8ee50ac55f282af229942fe4077b6434" title="Triangles list for the 3D face model.">faceModelTriangles</a>,<a class="el" href="structVisageSDK_1_1FaceData.html#aad53581671d541e68e7bf9e4619d3274" title="Texture coordinates for the 3D face model.">faceModelTextureCoords</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00652">652</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="ab5fe0bbe5ca937e2f2070c9fe07f3b82"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float VisageSDK::FaceData::faceRotation[3]</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Rotation of the head. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>This is the estimated rotation of the head, in radians. Rotation is expressed with three values determining the rotations around the three axes x, y and z, in radians. This means that the values represent the pitch, yaw and roll of the head, respectively. The zero rotation (values 0, 0, 0) corresponds to the face looking straight ahead along the camera axis. Positive values for pitch correspond to head turning down. Positive values for yaw correspond to head turning right in the input image. Positive values for roll correspond to head rolling to the left in the input image, see illustration below. The values are in radians.</p>
<div class="image">
<img src="./../images/coord-rotation.png" alt="coord-rotation.png"/>
</div>
 <dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a854b784b183fa4021e713506deff9845" title="Translation of the head from the camera.">faceTranslation</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00359">359</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l00563">VisageSDK::VisageRendering::DisplayFeaturePoints()</a>, <a class="el" href="VisageRendering_8cpp_source.html#l00976">VisageSDK::VisageRendering::DisplayModelAxes()</a>, and <a class="el" href="VisageRendering_8cpp_source.html#l01045">VisageSDK::VisageRendering::DisplayWireFrame()</a>.</p>

</div>
</div>
<a class="anchor" id="a49182e24cf549a1d6c7506b5316e60d5"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageSDK::FaceData::faceScale</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Scale of facial bounding box. </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00693">693</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a854b784b183fa4021e713506deff9845"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float VisageSDK::FaceData::faceTranslation[3]</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Translation of the head from the camera. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>Translation is expressed with three coordinates x, y, z. The coordinate system is such that when looking towards the camera, the direction of x is to the left, y iz up, and z points towards the viewer - see illustration below. The global origin (0,0,0) is placed at the camera. The reference point on the head is in the center between the eyes.</p>
<div class="image">
<img src="./../images/coord-camera.png" alt="coord-camera.png"/>
</div>
 <p>If the value set for the camera focal length in the <a href="../VisageTracker Configuration Manual.pdf">tracker/detector configuration</a> file corresponds to the real camera used, the returned coordinates shall be in meters; otherwise the scale of the translation values is not known, but the relative values are still correct (i.e. moving towards the camera results in smaller values of z coordinate).</p>
<p><b>Aligning 3D objects with the face</b></p>
<p>The translation, rotation and the camera focus value together form the 3D coordinate system of the head in its current position and they can be used to align 3D rendered objects with the head for AR or similar applications. This <a href="../ar-notes.cpp">example code</a> shows how to do this using OpenGL.</p>
<p>The relative facial feature coordinates (featurePoints3DRelative) can then be used to align rendered 3D objects to the specific features of the face, like putting virtual eyeglasses on the eyes. Samples projects demonstrate how to do this, including full source code.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#ab5fe0bbe5ca937e2f2070c9fe07f3b82" title="Rotation of the head.">faceRotation</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00312">312</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l00563">VisageSDK::VisageRendering::DisplayFeaturePoints()</a>, <a class="el" href="VisageRendering_8cpp_source.html#l00976">VisageSDK::VisageRendering::DisplayModelAxes()</a>, and <a class="el" href="VisageRendering_8cpp_source.html#l01045">VisageSDK::VisageRendering::DisplayWireFrame()</a>.</p>

</div>
</div>
<a class="anchor" id="a98c7a959cbde274d14a92ef191e7758c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classVisageSDK_1_1FDP.html">FDP</a>* VisageSDK::FaceData::featurePoints2D</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Facial feature points (2D coordinates). </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>The 2D feature point coordinates are normalised to image size so that the lower left corner of the image has coordinates 0,0 and upper right corner 1,1.</p>
<p>The feature points are identified according to the MPEG-4 standard, so each feature point is identified by its group and index. For example, the tip of the chin belongs to group 2 and its index is 1, so this point is identified as point 2.1. The identification of all feature points is illustrated in the following image: </p>
<div class="image">
<img src="../images/mpeg-4_fba.png" alt="mpeg-4_fba.png"/>
</div>
<p>Certain feature points, like the ones on the tongue and teeth, can not be reliably detected so they are not returned and their coordinates are always set to zero. These points are: 6.1, 6.2, 6.3, 6.4, 9.8, 9.9, 9.10, 9.11, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 11.4, 11.5, 11.6.</p>
<p>Several other points are estimated, rather than accurately detected, due to their specific locations. These points are: 2.10, 2.11, 2.12, 2.13, 2.14, 5.1, 5.2, 5.3, 5.4, 7.1, 9.4, 9.5, 9.6, 9.7, 9.12, 9.13, 9.14, 10.7, 10.8, 10.9, 10.10, 11.1, 11.2, 11.3, 12.1.</p>
<p>When <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a> is obtained from the tracker and process_eyes parameter is set to '1' in the tracker configuration file, points 3.5 and 3.6 (pupils) are set to their detected values. If process_eyes is set to 0, points 3.5 and 3.6 are not detected and their coordinates are set to zero.</p>
<p>The resulting feature point coordinates are returned in form of an <a class="el" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> object. This is a container class used for storage of MPEG-4 feature points. It provides functions to access each feature point by its group and index and to read its coordinates. Note that <a class="el" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> stores 3D points and in the case of 2D feature points only the x and y coordinates of each point are used.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a1fd85018c51af5c63ac2d60eb6c9d91a" title="Facial feature points (global 3D coordinates).">featurePoints3D</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#ad64b091d44f2358f2cd0e86d7b627a99" title="Facial feature points (3D coordinates relative to the face origin, placed at the center between eyes)...">featurePoints3DRelative</a>, <a class="el" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00610">610</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a1fd85018c51af5c63ac2d60eb6c9d91a"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classVisageSDK_1_1FDP.html">FDP</a>* VisageSDK::FaceData::featurePoints3D</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Facial feature points (global 3D coordinates). </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>The coordinate system is such that when looking towards the camera, the direction of x is to the left, y iz up, and z points towards the viewer. The global origin (0,0,0) is placed at the camera, see illustration.</p>
<div class="image">
<img src="../images/coord-camera.png" alt="coord-camera.png"/>
</div>
 <p>If the value set for the camera focal length in the <a href="../VisageTracker Configuration Manual.pdf">tracker/detector configuration</a> file corresponds to the real camera used, the returned coordinates shall be in meters; otherwise the scale is not known, but the relative values are still correct (i.e. moving towards the camera results in smaller values of z coordinate).</p>
<p>The feature points are identified according to the MPEG-4 standard, so each feature point is identified by its group and index. For example, the tip of the chin belongs to group 2 and its index is 1, so this point is identified as point 2.1. The identification of all feature points is illustrated in the following image: </p>
<div class="image">
<img src="../images/mpeg-4_fba.png" alt="mpeg-4_fba.png"/>
</div>
<p>Certain feature points, like the ones on the tongue and teeth, can not be reliably detected so they are not returned and their coordinates are always set to zero. These points are: 6.1, 6.2, 6.3, 6.4, 9.8, 9.9, 9.10, 9.11, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 11.4, 11.5, 11.6.</p>
<p>Several other points are estimated, rather than accurately detected, due to their specific locations. These points are: 2.10, 2.11, 2.12, 2.13, 2.14, 5.1, 5.2, 5.3, 5.4, 7.1, 9.4, 9.5, 9.6, 9.7, 9.12, 9.13, 9.14, 10.7, 10.8, 10.9, 10.10, 11.1, 11.2, 11.3, 12.1.</p>
<p>The resulting feature point coordinates are returned in form of an <a class="el" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> object. This is a container class used for storage of MPEG-4 feature points. It provides functions to access each feature point by its group and index and to read its coordinates.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#ad64b091d44f2358f2cd0e86d7b627a99" title="Facial feature points (3D coordinates relative to the face origin, placed at the center between eyes)...">featurePoints3DRelative</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a98c7a959cbde274d14a92ef191e7758c" title="Facial feature points (2D coordinates).">featurePoints2D</a>, <a class="el" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00550">550</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l00890">VisageSDK::VisageRendering::DisplayGaze()</a>, and <a class="el" href="VisageRendering_8cpp_source.html#l00976">VisageSDK::VisageRendering::DisplayModelAxes()</a>.</p>

</div>
</div>
<a class="anchor" id="ad64b091d44f2358f2cd0e86d7b627a99"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classVisageSDK_1_1FDP.html">FDP</a>* VisageSDK::FaceData::featurePoints3DRelative</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Facial feature points (3D coordinates relative to the face origin, placed at the center between eyes). </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em></p>
<p>The coordinates are in the local coordinate system of the face, with the origin (0,0,0) placed at the center between the eyes. The x-axis points laterally towards the side of the face, y-xis points up and z-axis points into the face - see illustration below.</p>
<div class="image">
<img src="../images/coord.png" alt="coord.png"/>
</div>
 <p>The feature points are identified according to the MPEG-4 standard, so each feature point is identified by its group and index. For example, the tip of the chin belongs to group 2 and its index is 1, so this point is identified as point 2.1. The identification of all feature points is illustrated in the following image: </p>
<div class="image">
<img src="../images/mpeg-4_fba.png" alt="mpeg-4_fba.png"/>
</div>
<p>Certain feature points, like the ones on the tongue and teeth, can not be reliably detected so they are not returned and their coordinates are always set to zero. These points are: 6.1, 6.2, 6.3, 6.4, 9.8, 9.9, 9.10, 9.11, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 11.4, 11.5, 11.6.</p>
<p>Several other points are estimated, rather than accurately detected, due to their specific locations. These points are: 2.10, 2.11, 2.12, 2.13, 2.14, 5.1, 5.2, 5.3, 5.4, 7.1, 9.4, 9.5, 9.6, 9.7, 9.12, 9.13, 9.14, 10.7, 10.8, 10.9, 10.10, 11.1, 11.2, 11.3, 12.1.</p>
<p>The resulting feature point coordinates are returned in form of an <a class="el" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> object. This is a container class used for storage of MPEG-4 feature points. It provides functions to access each feature point by its group and index and to read its coordinates.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a1fd85018c51af5c63ac2d60eb6c9d91a" title="Facial feature points (global 3D coordinates).">featurePoints3D</a> <a class="el" href="structVisageSDK_1_1FaceData.html#a98c7a959cbde274d14a92ef191e7758c" title="Facial feature points (2D coordinates).">featurePoints2D</a>, <a class="el" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00580">580</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a306fc247ad6223a52c1a840531680c1a"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">IplImage* VisageSDK::FaceData::frame</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pointer to the video frame associated with the current data, or NULL if tracker is not active. </p>
<p><em>This variable is set while tracker is running., i.e. while tracking status is not TRACK_STAT_OFF. Face detector sets this variable if face is detected.</em></p>
<p>IplImage is the image storage class from OpenCV, please refer to OpenCV documentation for details of accessing its data members; the basic members are the size of the image (frame-&gt;width, frame-&gt;height) and the pointer to the actual pixel data of the image (frame-&gt;imageData).</p>
<p>Note: For performance reasons frame is passed only as a pointer, i.e. actual image data is not copied into <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a> structure. The tracker uses a triple buffer mechanism, so the frame will be valid for at least the duration of two video frames. If frame is used later than that, it may point to a new image, not corresponding to the rest of the tracking data. </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00690">690</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l01145">VisageSDK::VisageRendering::DisplayResults()</a>.</p>

</div>
</div>
<a class="anchor" id="a7138a72d57adc5ddb75d757bf0653dc1"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float VisageSDK::FaceData::frameRate</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The frame rate of the tracker, in frames per second, measured over last 10 frames. </p>
<p><em>This variable is set while tracker is running., i.e. while tracking status is not TRACK_STAT_OFF. Face detector leaves this variable undefined.</em> </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00273">273</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="afa666a789971fb67bd4e485c505ba61b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">ScreenSpaceGazeData VisageSDK::FaceData::gazeData</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Structure holding screen space gaze position and quality for current frame. </p>
<p><em>This value is set while tracker is running or if the detector has detected a face.</em></p>
<p>Position values are dependent on estimator state. Please refer to <a class="el" href="classVisageSDK_1_1VisageGazeTracker.html" title="VisageGazeTracker extends VisageTracker2 functionality, adding screen space gaze tracking on top of f...">VisageGazeTracker</a> and ScreenSpaceGazeData documentation for more details. </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00727">727</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a756d9a030db04d3e8686d8edd9c385ef"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float VisageSDK::FaceData::gazeDirection[2]</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gaze direction. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK). Face detector leaves this variable undefined.</em></p>
<p>This is the current estimated gaze direction relative to the person's head. Direction is expressed with two values x and y, in radians. Values (0, 0) correspond to person looking straight. X is the horizontal rotation with positive values coresponding to person looking to his/her left. Y is the vertical rotation with positive values coresponding to person looking down.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a163adbed757c776cf6ce7556ec226e58" title="Global gaze direction, taking into account both head pose and eye rotation.">gazeDirectionGlobal</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00372">372</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a163adbed757c776cf6ce7556ec226e58"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float VisageSDK::FaceData::gazeDirectionGlobal[3]</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Global gaze direction, taking into account both head pose and eye rotation. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK). Face detector leaves this variable undefined.</em></p>
<p>This is the current estimated gaze direction relative to the camera axis. Direction is expressed with three values determining the rotations around the three axes x, y and z, i.e. pitch, yaw and roll. Values (0, 0, 0) correspond to the gaze direction parallel to the camera axis. Positive values for pitch correspond to gaze turning down. Positive values for yaw correspond to gaze turning right in the input image. Positive values for roll correspond to face rolling to the left in the input image, see illustration below.</p>
<p>The values are in radians.</p>
<div class="image">
<img src="./../images/coord-rotation-eye.png" alt="coord-rotation-eye.png"/>
</div>
 <p>The global gaze direction can be combined with eye locations to determine the line(s) of sight in the real-world coordinate system with the origin at the camera. To get eye positions use <a class="el" href="structVisageSDK_1_1FaceData.html#a1fd85018c51af5c63ac2d60eb6c9d91a" title="Facial feature points (global 3D coordinates).">featurePoints3D</a> and <a class="el" href="classVisageSDK_1_1FDP.html#a1a5507ba8c4fe8f640e63714e93e1757" title="Get a feature point by its group and index.">FDP::getFP()</a> function, e.g.:</p>
<div class="fragment"><div class="line">FeaturePoint *left_eye_fp = <span class="keyword">const_cast&lt;</span>FeaturePoint*<span class="keyword">&gt;</span>( &amp;<a class="code" href="structVisageSDK_1_1FaceData.html#a1fd85018c51af5c63ac2d60eb6c9d91a" title="Facial feature points (global 3D coordinates).">featurePoints3D</a>-&gt;<a class="code" href="classVisageSDK_1_1FDP.html#a1a5507ba8c4fe8f640e63714e93e1757" title="Get a feature point by its group and index.">getFP</a>(3,5) );</div>
<div class="line">FeaturePoint *right_eye_fp = <span class="keyword">const_cast&lt;</span>FeaturePoint*<span class="keyword">&gt;</span>( &amp;<a class="code" href="structVisageSDK_1_1FaceData.html#a1fd85018c51af5c63ac2d60eb6c9d91a" title="Facial feature points (global 3D coordinates).">featurePoints3D</a>-&gt;<a class="code" href="classVisageSDK_1_1FDP.html#a1a5507ba8c4fe8f640e63714e93e1757" title="Get a feature point by its group and index.">getFP</a>(3,6) );</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">float</span> left_eye_pos[3], right_eye_pos[3];</div>
<div class="line"></div>
<div class="line">left_eye_pos[0]  = left_eye_fp-&gt;pos[0];  <span class="comment">// x</span></div>
<div class="line">left_eye_pos[1]  = left_eye_fp-&gt;pos[1];  <span class="comment">// y</span></div>
<div class="line">left_eye_pos[2]  = left_eye_fp-&gt;pos[2];  <span class="comment">// z</span></div>
<div class="line">right_eye_pos[0] = right_eye_fp-&gt;pos[0]; <span class="comment">// x</span></div>
<div class="line">right_eye_pos[1] = right_eye_fp-&gt;pos[1]; <span class="comment">// y</span></div>
<div class="line">right_eye_pos[2] = right_eye_fp-&gt;pos[2]; <span class="comment">// z</span></div>
</div><!-- fragment --><dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a756d9a030db04d3e8686d8edd9c385ef" title="Gaze direction.">gazeDirection</a>, <a class="el" href="structVisageSDK_1_1FaceData.html#a1fd85018c51af5c63ac2d60eb6c9d91a" title="Facial feature points (global 3D coordinates).">featurePoints3D</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00409">409</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

<p>Referenced by <a class="el" href="VisageRendering_8cpp_source.html#l00890">VisageSDK::VisageRendering::DisplayGaze()</a>.</p>

</div>
</div>
<a class="anchor" id="a0c65746338cc1236659c950014b02f9d"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageSDK::FaceData::shapeUnitCount</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of facial Shape Units. </p>
<p><em>This variable is set while tracker is running., i.e. while tracking status is not TRACK_STAT_OFF or if the detector has detected a face.</em>.</p>
<p>Number of shape units that are defined for current face model.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a7bc3d34519d420010cab7829c5d24b85" title="List of current values for facial Shape Units, one value for each shape unit.">shapeUnits</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00427">427</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a7bc3d34519d420010cab7829c5d24b85"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float* VisageSDK::FaceData::shapeUnits</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>List of current values for facial Shape Units, one value for each shape unit. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK) or if the detector has detected a face.</em>.</p>
<p>Shape units can be described as static parameters of the face that are specific for each individual (e.g. shape of the nose).</p>
<p>The shape units used by the tracker and detector are defined in the 3D face model file (currently, Candide3.wfm is used ; tracker and detector can be configured to use another file see the <a href="../VisageTracker Configuration Manual.pdf">VisageTracker Configuration Manual</a> for details).</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html#a0c65746338cc1236659c950014b02f9d" title="Number of facial Shape Units.">shapeUnitCount</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00442">442</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="af7afec396f9581356cc0b8fea4a10b9b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">long VisageSDK::FaceData::timeStamp</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Timestamp of the current video frame. </p>
<p><em>This variable is set while tracker is running., i.e. while tracking status is not TRACK_STAT_OFF. Face detector leaves this variable undefined.</em></p>
<p>When tracking from camera, timeStamp returns time, in milliseconds, measured from the moment when tracking started. When tracking from video, timeStamp returns the time of the current video frame, in milliseconds. When tracking from raw images, timeStamp returns the value it received from the <a class="el" href="classVisageSDK_1_1VisageTrackerFrameGrabber.html#aadce06772d63f30739606c67e6f1a663" title="Frame grabbing function (virtual - to be implemented by the application).">VisageTrackerFrameGrabber::GrabFrame()</a> function if it is different than -1, otherwise it returns time, in milliseconds, measured from the moment when tracking started.</p>
<dl class="section see"><dt>See Also</dt><dd><a class="el" href="classVisageSDK_1_1VisageTrackerFrameGrabber.html" title="DEPRECATED, This interface is deprecated and replaced with VisageTracker2::track() API...">VisageTrackerFrameGrabber</a> </dd></dl>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00283">283</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<a class="anchor" id="a6aca0c311aeb0b3ee0eead93546235dd"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float VisageSDK::FaceData::trackingQuality</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Tracking quality level. </p>
<p><em>This variable is set only while tracker is tracking (TRACK_STAT_OK). Face detector leaves this variable undefined.</em></p>
<p>Estimated tracking quality level for the current frame. The value is between 0 and 1, and it corresponds to the global_bad_match_threshold parameter in the <a href="../VisageTracker Configuration Manual.pdf">tracker configuration file</a>, i.e. the quality measure is checked against this threshold and when it falls below the tracker resets itself. </p>

<p>Definition at line <a class="el" href="FaceData_8h_source.html#l00266">266</a> of file <a class="el" href="FaceData_8h_source.html">FaceData.h</a>.</p>

</div>
</div>
<hr/>The documentation for this struct was generated from the following file:<ul>
<li><a class="el" href="FaceData_8h_source.html">FaceData.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Nov 20 2015 16:28:36 for visageSDK by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.2
</small></address>
</body>
</html>
